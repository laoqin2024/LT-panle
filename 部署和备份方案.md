# 部署和备份方案

## 一、云端部署管理内网设备方案

### 1.1 当前架构分析

#### ✅ 支持的功能
- **SSH/Telnet连接**: 可以通过公网IP或VPN连接到内网设备
- **SNMP监控**: 如果设备支持SNMP且端口开放，可以通过公网访问
- **数据库连接**: 支持通过公网IP连接数据库（需要网络可达）

#### ⚠️ 需要改进的地方
- **内网设备访问**: 需要配置网络连接方案
- **安全连接**: 需要VPN或跳板机
- **网络穿透**: 可能需要内网穿透方案

### 1.2 推荐部署架构

#### 方案A：VPN方案（推荐）

**架构图**:
```
云端服务器 (Laoqin Panel)
    ↓ VPN隧道
内网VPN网关
    ↓ 内网
[服务器] [网络设备] [数据库]
```

**优点**:
- 安全性高，加密传输
- 支持所有内网设备
- 无需修改设备配置

**实现方式**:
1. 在云端服务器部署VPN客户端
2. 连接到内网VPN网关
3. 通过VPN隧道访问内网设备

**配置示例**:
```python
# 使用OpenVPN或WireGuard
# 在服务器上配置VPN客户端
# 连接后，内网设备可以通过内网IP访问
```

#### 方案B：跳板机方案

**架构图**:
```
云端服务器 (Laoqin Panel)
    ↓ SSH隧道
内网跳板机 (有公网IP)
    ↓ 内网
[服务器] [网络设备] [数据库]
```

**优点**:
- 实现简单
- 只需要一台有公网IP的跳板机
- 支持SSH端口转发

**实现方式**:
```python
# SSH隧道配置
# 通过跳板机建立SSH隧道访问内网设备
import paramiko

def create_ssh_tunnel(jump_host, target_host, target_port):
    """通过跳板机建立SSH隧道"""
    # 连接到跳板机
    jump_client = paramiko.SSHClient()
    jump_client.connect(jump_host['host'], jump_host['port'], 
                       jump_host['username'], jump_host['password'])
    
    # 建立端口转发
    transport = jump_client.get_transport()
    dest_addr = (target_host, target_port)
    local_addr = ('localhost', 0)
    channel = transport.open_channel('direct-tcpip', dest_addr, local_addr)
    
    return channel
```

#### 方案C：内网穿透方案

**架构图**:
```
云端服务器 (Laoqin Panel)
    ↓ 内网穿透服务 (frp/ngrok)
内网穿透客户端
    ↓ 内网
[服务器] [网络设备] [数据库]
```

**优点**:
- 无需VPN或跳板机
- 配置简单
- 支持动态IP

**实现方式**:
- 使用frp、ngrok等内网穿透工具
- 在内网部署穿透客户端
- 云端通过穿透地址访问

### 1.3 数据库设计支持

#### 添加网络配置字段

```sql
-- 服务器表添加网络配置
ALTER TABLE servers ADD COLUMN network_type VARCHAR(50) DEFAULT 'direct';
-- 'direct': 直接连接
-- 'vpn': VPN连接
-- 'jump': 跳板机连接
-- 'tunnel': 内网穿透

ALTER TABLE servers ADD COLUMN jump_host_id INTEGER REFERENCES servers(id);
ALTER TABLE servers ADD COLUMN vpn_config JSONB;
ALTER TABLE servers ADD COLUMN tunnel_config JSONB;

-- 网络设备表同样添加
ALTER TABLE network_devices ADD COLUMN network_type VARCHAR(50) DEFAULT 'direct';
ALTER TABLE network_devices ADD COLUMN jump_host_id INTEGER REFERENCES servers(id);
```

### 1.4 实现建议

**第一阶段**: 支持跳板机连接
- 添加跳板机配置
- 实现SSH隧道功能
- 支持通过跳板机连接内网设备

**第二阶段**: 支持VPN连接
- 集成VPN客户端
- 自动建立VPN连接
- 通过VPN访问内网设备

**第三阶段**: 支持内网穿透
- 集成内网穿透服务
- 自动配置穿透地址
- 动态更新连接地址

---

## 二、快速数据迁移方案

### 2.1 数据导出功能

#### 导出内容
- 数据库数据（PostgreSQL）
- 配置文件
- 上传的文件
- 备份文件

#### 导出格式
- **数据库**: SQL转储文件（pg_dump）
- **配置**: JSON/YAML文件
- **文件**: 压缩包（tar.gz）

#### 实现代码

```python
# app/services/backup_service.py
import subprocess
import json
import tarfile
from datetime import datetime
from pathlib import Path

class BackupService:
    def __init__(self, db_url: str, backup_dir: str):
        self.db_url = db_url
        self.backup_dir = Path(backup_dir)
        self.backup_dir.mkdir(exist_ok=True)
    
    def export_all_data(self) -> str:
        """导出所有数据"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        backup_name = f"laoqin_panel_backup_{timestamp}"
        backup_path = self.backup_dir / backup_name
        backup_path.mkdir()
        
        # 1. 导出数据库
        db_file = backup_path / "database.sql"
        self.export_database(db_file)
        
        # 2. 导出配置
        config_file = backup_path / "config.json"
        self.export_config(config_file)
        
        # 3. 导出文件
        files_dir = backup_path / "files"
        self.export_files(files_dir)
        
        # 4. 打包
        archive = f"{backup_name}.tar.gz"
        self.create_archive(backup_path, archive)
        
        return archive
    
    def export_database(self, output_file: Path):
        """导出数据库"""
        subprocess.run([
            'pg_dump',
            self.db_url,
            '-F', 'c',  # 自定义格式
            '-f', str(output_file)
        ], check=True)
    
    def export_config(self, output_file: Path):
        """导出配置"""
        config = {
            'settings': self.get_all_settings(),
            'credentials': self.get_credentials_metadata(),  # 不包含密码
        }
        with open(output_file, 'w') as f:
            json.dump(config, f, indent=2)
    
    def export_files(self, output_dir: Path):
        """导出上传的文件"""
        files_dir = Path('uploads')
        if files_dir.exists():
            import shutil
            shutil.copytree(files_dir, output_dir)
```

### 2.2 数据导入功能

#### 导入流程
1. 上传备份文件
2. 解压备份文件
3. 验证数据完整性
4. 导入数据库
5. 恢复配置文件
6. 恢复文件

#### 实现代码

```python
class RestoreService:
    def __init__(self, db_url: str, backup_file: str):
        self.db_url = db_url
        self.backup_file = backup_file
        self.temp_dir = Path('/tmp/restore')
    
    def restore_all_data(self):
        """恢复所有数据"""
        # 1. 解压备份文件
        self.extract_backup()
        
        # 2. 验证数据
        self.validate_backup()
        
        # 3. 备份当前数据（安全措施）
        self.backup_current_data()
        
        # 4. 恢复数据库
        self.restore_database()
        
        # 5. 恢复配置
        self.restore_config()
        
        # 6. 恢复文件
        self.restore_files()
        
        # 7. 清理临时文件
        self.cleanup()
    
    def restore_database(self):
        """恢复数据库"""
        db_file = self.temp_dir / "database.sql"
        subprocess.run([
            'pg_restore',
            '-d', self.db_url,
            '-c',  # 清理现有数据
            str(db_file)
        ], check=True)
```

### 2.3 前端界面

#### 数据迁移页面

```typescript
// pages/BackupRestore.tsx
- 导出数据按钮
- 导入数据上传
- 迁移进度显示
- 迁移历史记录
```

### 2.4 API设计

```
POST /api/backup/export          # 导出数据
POST /api/backup/import           # 导入数据
GET  /api/backup/list            # 备份列表
GET  /api/backup/{id}/download   # 下载备份
DELETE /api/backup/{id}          # 删除备份
```

---

## 三、快速恢复方案

### 3.1 自动备份策略

#### 备份频率
- **数据库**: 每天自动备份
- **配置文件**: 每次修改时备份
- **完整备份**: 每周一次

#### 备份存储
- **本地存储**: 服务器本地目录
- **远程存储**: 
  - 对象存储（S3/OSS）
  - FTP/SFTP服务器
  - 云盘同步

#### 实现代码

```python
# app/tasks/backup_tasks.py
from celery import Celery
from app.services.backup_service import BackupService
import boto3  # 如果使用S3

celery_app = Celery('backup')

@celery_app.task
def daily_backup():
    """每日自动备份"""
    service = BackupService(db_url, backup_dir)
    backup_file = service.export_all_data()
    
    # 上传到远程存储
    upload_to_remote(backup_file)
    
    # 清理旧备份（保留30天）
    cleanup_old_backups(days=30)

@celery_app.task
def weekly_full_backup():
    """每周完整备份"""
    service = BackupService(db_url, backup_dir)
    backup_file = service.export_all_data()
    
    # 上传到多个存储位置
    upload_to_s3(backup_file)
    upload_to_ftp(backup_file)
```

### 3.2 一键恢复功能

#### 恢复流程
1. 选择备份文件（本地或远程）
2. 验证备份文件完整性
3. 停止服务（可选）
4. 恢复数据库
5. 恢复配置文件
6. 恢复文件
7. 重启服务
8. 验证恢复结果

#### 实现代码

```python
# app/api/backup.py
from fastapi import APIRouter, UploadFile, File
from app.services.restore_service import RestoreService

router = APIRouter()

@router.post("/restore")
async def restore_backup(
    backup_file: UploadFile = File(...),
    source: str = "local"  # 'local' or 'remote'
):
    """一键恢复"""
    if source == "remote":
        # 从远程存储下载
        backup_file = download_from_remote(backup_id)
    
    service = RestoreService(db_url, backup_file)
    result = service.restore_all_data()
    
    return {
        "status": "success",
        "message": "数据恢复成功",
        "restored_at": datetime.now().isoformat()
    }
```

### 3.3 备份管理界面

#### 功能
- 查看备份列表
- 手动创建备份
- 下载备份文件
- 从备份恢复
- 删除旧备份
- 备份策略配置

### 3.4 灾难恢复流程

#### 场景：服务器损坏，需要重新部署

**步骤1: 准备新服务器**
```bash
# 1. 安装Docker和Docker Compose
# 2. 克隆项目代码
git clone <repository>
cd laoqin-panel

# 3. 配置环境变量
cp .env.example .env
# 编辑.env文件，配置数据库等
```

**步骤2: 恢复数据**
```bash
# 1. 启动数据库服务（不启动应用）
docker-compose up -d postgres redis

# 2. 下载最新备份
# 从S3/OSS/FTP下载备份文件

# 3. 恢复数据
docker-compose exec backend python -m app.scripts.restore backup_file.tar.gz

# 4. 启动所有服务
docker-compose up -d
```

**步骤3: 验证恢复**
- 检查数据完整性
- 测试功能
- 验证连接

### 3.5 数据库设计

```sql
-- 备份记录表
CREATE TABLE backups (
    id SERIAL PRIMARY KEY,
    backup_name VARCHAR(255) NOT NULL,
    backup_type VARCHAR(50) NOT NULL,  -- 'manual', 'daily', 'weekly'
    file_path TEXT,
    file_size BIGINT,
    status VARCHAR(50) DEFAULT 'completed',  -- 'completed', 'failed', 'in_progress'
    created_at TIMESTAMP DEFAULT NOW(),
    created_by INTEGER REFERENCES users(id),
    metadata JSONB  -- 备份元数据
);

-- 恢复记录表
CREATE TABLE restores (
    id SERIAL PRIMARY KEY,
    backup_id INTEGER REFERENCES backups(id),
    status VARCHAR(50) DEFAULT 'in_progress',
    started_at TIMESTAMP DEFAULT NOW(),
    completed_at TIMESTAMP,
    restored_by INTEGER REFERENCES users(id),
    error_message TEXT
);
```

---

## 四、Docker部署方案

### 4.1 Docker Compose配置

```yaml
# docker-compose.yml
version: '3.8'

services:
  postgres:
    image: timescale/timescaledb:latest-pg15
    environment:
      POSTGRES_USER: laoqin
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: laoqin_panel
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./backups:/backups  # 备份目录
    ports:
      - "5432:5432"
    restart: unless-stopped

  redis:
    image: redis:7-alpine
    volumes:
      - redis_data:/data
    restart: unless-stopped

  backend:
    build: ./backend
    environment:
      DATABASE_URL: postgresql://laoqin:${POSTGRES_PASSWORD}@postgres:5432/laoqin_panel
      REDIS_URL: redis://redis:6379
      ENCRYPTION_KEY: ${ENCRYPTION_KEY}
    volumes:
      - ./uploads:/app/uploads
      - ./backups:/app/backups
    depends_on:
      - postgres
      - redis
    restart: unless-stopped

  frontend:
    build: ./frontend
    ports:
      - "80:80"
    depends_on:
      - backend
    restart: unless-stopped

  # 备份服务（可选，使用Cron）
  backup:
    image: postgres:15
    volumes:
      - ./backups:/backups
      - ./scripts:/scripts
    command: >
      sh -c "
        echo '0 2 * * * /scripts/backup.sh' | crontab -
        crond -f
      "
    depends_on:
      - postgres

volumes:
  postgres_data:
  redis_data:
```

### 4.2 备份脚本

```bash
#!/bin/bash
# scripts/backup.sh

BACKUP_DIR="/backups"
TIMESTAMP=$(date +%Y%m%d_%H%M%S)
BACKUP_FILE="backup_${TIMESTAMP}.sql"

# 备份数据库
pg_dump -h postgres -U laoqin laoqin_panel > "${BACKUP_DIR}/${BACKUP_FILE}"

# 压缩备份
gzip "${BACKUP_DIR}/${BACKUP_FILE}"

# 上传到远程存储（可选）
# aws s3 cp "${BACKUP_DIR}/${BACKUP_FILE}.gz" s3://backup-bucket/

# 清理旧备份（保留30天）
find "${BACKUP_DIR}" -name "backup_*.sql.gz" -mtime +30 -delete
```

### 4.3 恢复脚本

```bash
#!/bin/bash
# scripts/restore.sh

BACKUP_FILE=$1

if [ -z "$BACKUP_FILE" ]; then
    echo "Usage: restore.sh <backup_file>"
    exit 1
fi

# 解压备份文件
gunzip "${BACKUP_FILE}"

# 恢复数据库
psql -h postgres -U laoqin laoqin_panel < "${BACKUP_FILE%.gz}"

echo "恢复完成"
```

---

## 五、实施建议

### 5.1 优先级

**高优先级（必须实现）**:
1. ✅ 数据库自动备份
2. ✅ 数据导出/导入功能
3. ✅ 一键恢复功能
4. ✅ Docker部署配置

**中优先级（建议实现）**:
1. ⚠️ 跳板机连接支持
2. ⚠️ 远程备份存储
3. ⚠️ 备份管理界面

**低优先级（可选实现）**:
1. ⚠️ VPN连接支持
2. ⚠️ 内网穿透支持
3. ⚠️ 增量备份

### 5.2 开发步骤

**第一阶段（1周）**:
- 实现数据库备份/恢复功能
- 添加备份管理API
- 创建备份管理页面

**第二阶段（1周）**:
- 实现跳板机连接
- 添加网络配置管理
- 测试内网设备访问

**第三阶段（1周）**:
- 实现远程备份存储
- 添加自动备份任务
- 完善恢复流程

---

## 六、总结

### 6.1 当前架构支持情况

| 功能 | 支持情况 | 需要改进 |
|------|---------|---------|
| 云端部署管理内网设备 | ⚠️ 部分支持 | 需要添加跳板机/VPN支持 |
| 快速数据迁移 | ❌ 不支持 | 需要实现导出/导入功能 |
| 快速恢复 | ❌ 不支持 | 需要实现备份/恢复功能 |

### 6.2 推荐方案

1. **内网设备访问**: 使用跳板机方案（简单实用）
2. **数据迁移**: 实现完整的导出/导入功能
3. **快速恢复**: 自动备份 + 一键恢复

### 6.3 安全建议

1. ✅ 备份文件加密存储
2. ✅ 备份文件访问权限控制
3. ✅ 恢复操作需要管理员权限
4. ✅ 恢复前自动备份当前数据
5. ✅ 备份文件定期清理

这个方案可以满足你的所有需求，建议按优先级逐步实现。

